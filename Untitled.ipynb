{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_point1 = (400,0)\n",
    "line_point2 = (400,500)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "#in this case above the line and inbetween the two points is considered in\n",
    "\n",
    "ENTERED_STRING = \"ENTERED_THE_AREA\"\n",
    "LEFT_AREA_STRING = \"LEFT_THE_AREA\"\n",
    "NO_CHANGE_STRING = \"NOTHIN_HOMEBOY\"\n",
    "\n",
    "LOWEST_CLOSEST_DISTANCE_THRESHOLD = 100\n",
    "\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "frame_count = 0\n",
    "people_list = []\n",
    "inside_count = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "\n",
    "    positions = []\n",
    "\n",
    "    def __init__(self, position):\n",
    "        self.positions = [position]\n",
    "\n",
    "    def update_position(self, new_position):\n",
    "        self.positions.append(new_position)\n",
    "        if len(self.positions) > 100:\n",
    "            self.positions.pop(0)\n",
    "\n",
    "\n",
    "    def on_opposite_sides(self):\n",
    "        return ((self.positions[-2][0] > line_point1[0] and self.positions[-1][0] <= line_point1[0])\n",
    "                or (self.positions[-2][0] <= line_point1[0] and self.positions[-1][0] > line_point1[0]))\n",
    "\n",
    "    def did_cross_line(self):\n",
    "        if self.on_opposite_sides():\n",
    "            if self.positions[-1][0] > line_point1[0]:\n",
    "                return ENTERED_STRING\n",
    "            else:\n",
    "                return LEFT_AREA_STRING\n",
    "        else:\n",
    "            return NO_CHANGE_STRING\n",
    "\n",
    "    def distance_from_last_x_positions(self, new_position, x):\n",
    "        total = [0,0]\n",
    "        z = x\n",
    "        while z > 0:\n",
    "            if (len(self.positions) > z):\n",
    "                total[0] +=  self.positions[-(z+1)][0]\n",
    "                total[1] +=  self.positions[-(z+1)][1]\n",
    "            else:\n",
    "                x -= 1\n",
    "            z -= 1\n",
    "        if total[0] < 1 or total[1] < 1:\n",
    "            return abs(self.positions[0][0] - new_position[0]) + abs(self.positions[0][1] - new_position[1])\n",
    "        total[0] = total[0] / x\n",
    "        total[1] = total[1] / x\n",
    "\n",
    "        return abs(new_position[0] - total[0]) + abs(new_position[1] - total[1])\n",
    "\n",
    "\n",
    "def get_footage():\n",
    "    return cv2.VideoCapture('./People-Counter-1/videos/solo_person_walking.mp4')\n",
    "\n",
    "def find_foreground_objects(background_model):\n",
    "    thresh = cv2.threshold(background_model, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    thresh = cv2.dilate(thresh, None, iterations=3)\n",
    "    thresh = cv2.erode(thresh, None, iterations=10)\n",
    "#     cv2.imshow(\"Foreground Mfasdfaodel\", thresh)\n",
    "\n",
    "\n",
    "    (_, cnts, _) = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return cnts\n",
    "\n",
    "def pipeline(img):\n",
    "#     camera = get_footage()\n",
    "    global fgbg \n",
    "    global frame_count \n",
    "    global people_list \n",
    "    global inside_count\n",
    "\n",
    "    if True:\n",
    "\n",
    "#         (grabbed, frame) = camera.read()\n",
    "#         if not grabbed:\n",
    "#             break\n",
    "        frame = np.copy(img)\n",
    "        frame = imutils.resize(frame, width=500)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        print(frame_count)\n",
    "\n",
    "        filtered_frame = cv2.GaussianBlur(frame, (21, 21), 0)\n",
    "        fgmask = fgbg.apply(filtered_frame)\n",
    "\n",
    "        foreground_objects = find_foreground_objects(fgmask)\n",
    "\n",
    "        for c in foreground_objects:\n",
    "            if cv2.contourArea(c) < 5000:\n",
    "                continue\n",
    "\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            lowest_closest_distance = float(\"inf\")\n",
    "            rectangle_center = (np.int(((2 * x) + w)/2), np.int(((2 * y) + h)/2))\n",
    "            cv2.circle(frame, rectangle_center, 2, (0, 0, 255))\n",
    "            closest_person_index = None\n",
    "\n",
    "\n",
    "            for i in range(0, len(people_list)):\n",
    "                if people_list[i].distance_from_last_x_positions(rectangle_center, 5) < lowest_closest_distance:\n",
    "                    lowest_closest_distance = people_list[i].distance_from_last_x_positions(rectangle_center, 5)\n",
    "                    closest_person_index = i\n",
    "            if closest_person_index is not None:\n",
    "                if lowest_closest_distance < LOWEST_CLOSEST_DISTANCE_THRESHOLD:\n",
    "                    people_list[i].update_position(rectangle_center)\n",
    "                    change = people_list[i].did_cross_line()\n",
    "                    if change == ENTERED_STRING:\n",
    "                        inside_count += 1\n",
    "                    elif change == LEFT_AREA_STRING:\n",
    "                        inside_count -= 1\n",
    "                else:\n",
    "                    new_person = Person(rectangle_center)\n",
    "                    people_list.append(new_person)\n",
    "            else:\n",
    "                new_person = Person(rectangle_center)\n",
    "                people_list.append(new_person)\n",
    "\n",
    "\n",
    "        cv2.putText(frame, \"Number of people inside: {}\".format(inside_count), (10, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "        cv2.line(frame, line_point1, line_point2, (255, 0, 0), 2)\n",
    "        return frame\n",
    "#         cv2.imshow(\"Security Feed\", frame)\n",
    "#         cv2.imshow(\"Foreground Model\", fgmask)\n",
    "#         plt.imshow(frame)\n",
    "#         plt.axis('off')\n",
    "\n",
    "\n",
    "#         key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "#         if key == ord(\"q\"):\n",
    "#             break\n",
    "#     plt.show()\n",
    "#     camera.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on Video\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_output = './project_video_output_2.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"./videos/test_vid1.mp4\")\n",
    "white_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
